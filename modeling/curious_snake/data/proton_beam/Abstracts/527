Since metal-oxide-semiconductor field effect transistors (MOSFETs) medical applications in radiotherapy and radiology are gaining popularity, evaluating them under radiation of different energies is of major interest. This study aims at a characterization of MOSFET sensitivity with regard to total integrated dose. Sensitivity is expressed by the water calibration factor (CFw) and allows the user to associate the voltage difference reading displayed by the device to a dose value in water at the MOSFET location. The CFw of seven p-type dual-bias MOSFETs were measured for several accumulated doses. The radiation sources used were a 60Co unit ((E)gamma: 1.25 MeV), an 192Ir high dose rate unit ((E)gamma: 380 keV), and an orthovoltage unit providing two x-ray energy spectra for tube voltages of 30 kV((E)gamma:14.8 KeV) and 150 kV((E)gamma:70.1 keV). The CFw value diminishes with increasing threshold voltage, especially for low-energy radiation. It was stable for 60Co irradiations, while it decreased 6%, 5%, and 15% for beam energies of 192Ir, 150 kV, and 30 kV, respectively. The decrease rate is higher for the first half of the device lifetime. This behavior is explained by an alteration of the effective electric field applied to the MOSFET during irradiation, caused by the accumulation of holes at the Si-SiO2 interface. It is strongly dependent on the nature of the radiation, and particularly affects low x-ray energies. A frequent calibration of the device for this radiation type is essential in order to achieve adequate measurement accuracy, especially in low-energy applications, such as superficial therapy, brachytherapy, and diagnostic and interventional radiology