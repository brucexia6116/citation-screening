A mathematical model is used to analyze mutant spectra for large mutations induced by low-LET radiation. The model equations are based mainly on two-break misrejoining that leads to deletions or translocations. It is assumed, as a working hypothesis, that the initial damage induced by low-LET radiation is located randomly in the genome. Specifically, we analyzed data for two hemizygous loci: CD59- mutants, mainly very large-scale deletions (>3 Mbp), in human-hamster hybrid cells, and data from the literature on those HPRT- mutants which involve at least deletion of the whole gene, and often of additional flanking markers (approximately 50-kbp to approximately 4.4-Mbp deletions). For five data sets, we estimated f, the probability that two given breaks on the same chromosome will misrejoin to make a deletion, as a function of the separation between the breaks. We found that f is larger for nearby breaks than for breaks that are more widely separated; i.e., there is a "proximity effect". For acute irradiation, the values of f determined from the data are consistent with the corresponding break misrejoining parameters found previously in quantitative modeling of chromosome aberrations. The value of f was somewhat smaller for protracted irradiation than for acute irradiation at a given total dose; i.e., the mutation data show a decrease that was smaller than expected for dose protraction by fractionation or low dose rate